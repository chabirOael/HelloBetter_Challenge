{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(plots_artefact_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(processed_dataset_path)[select_training_columns]\n",
    "train_categorical_columns = ['course', 'gender']\n",
    "for col in train_categorical_columns:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "X = data.drop('unsuccessful_outcome', axis=1)\n",
    "y = data['unsuccessful_outcome'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9333895\tbest: 0.9333895 (0)\ttotal: 27.3ms\tremaining: 27.3s\n",
      "200:\ttest: 0.9658510\tbest: 0.9663207 (176)\ttotal: 5.68s\tremaining: 22.6s\n",
      "400:\ttest: 0.9646909\tbest: 0.9663207 (176)\ttotal: 11.7s\tremaining: 17.5s\n",
      "600:\ttest: 0.9628728\tbest: 0.9663207 (176)\ttotal: 17.8s\tremaining: 11.8s\n",
      "800:\ttest: 0.9624902\tbest: 0.9663207 (176)\ttotal: 23.8s\tremaining: 5.92s\n",
      "999:\ttest: 0.9625367\tbest: 0.9663207 (176)\ttotal: 29.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9663207295\n",
      "bestIteration = 176\n",
      "\n",
      "Shrink model to first 177 iterations.\n",
      "MLflow Run ID: 1c98ca6f99e64daba617bdaaf272bb38\n"
     ]
    }
   ],
   "source": [
    "groups = data['course']\n",
    "\n",
    "# Split the dataset into a train-test set (80%, 20%)\n",
    "X_train_test, X_test, y_train_test, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "groups_train_test = groups.loc[X_train_test.index]\n",
    "\n",
    "# Initialize GroupKFold\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Placeholder for the best model and its score\n",
    "best_model = None\n",
    "best_score = -np.inf\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "mlflow.set_experiment(mlflow_experiment_name)\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Iterate over each fold\n",
    "    fold_number = 0\n",
    "    for train_idx, valid_idx in gkf.split(X_train_test, y_train_test, groups=groups_train_test):\n",
    "        fold_number += 1\n",
    "        # Split the data\n",
    "        X_train, X_valid = X_train_test.iloc[train_idx], X_train_test.iloc[valid_idx]\n",
    "        y_train, y_valid = y_train_test.iloc[train_idx], y_train_test.iloc[valid_idx]\n",
    "\n",
    "        # Initialize CatBoostClassifier\n",
    "        catboost_model = CatBoostClassifier(\n",
    "            iterations=1000,\n",
    "            learning_rate=0.1,\n",
    "            depth=6,\n",
    "            loss_function='Logloss',\n",
    "            eval_metric='AUC',\n",
    "            random_seed=42,\n",
    "            verbose=200,\n",
    "            cat_features=train_categorical_columns,\n",
    "        )\n",
    "\n",
    "        # Fit model\n",
    "        catboost_model.fit(X_train, y_train, eval_set=(X_valid, y_valid), use_best_model=True)\n",
    "\n",
    "        # Evaluate model\n",
    "        y_pred = catboost_model.predict(X_test)\n",
    "        y_pred_proba = catboost_model.predict_proba(X_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        # Update best model if current model is better\n",
    "        if roc_auc > best_score:\n",
    "            best_model = catboost_model\n",
    "            best_score = roc_auc\n",
    "            plot_roc_curve(y_test, y_pred_proba)\n",
    "            plot_precision_recall_curve(y_test, y_pred_proba)\n",
    "            plot_confusion_matrix(y_test, y_pred)\n",
    "            plot_feature_importance(best_model, X_train)\n",
    "            plot_learning_curve(best_model)\n",
    "\n",
    "        # Log metrics to MLflow\n",
    "        mlflow.log_metric(f\"fold_{fold_number}_roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(f\"fold_{fold_number}_accuracy\", accuracy)\n",
    "        mlflow.log_metric(f\"fold_{fold_number}_precision\", precision)\n",
    "        mlflow.log_metric(f\"fold_{fold_number}_recall\", recall)\n",
    "        mlflow.log_metric(f\"fold_{fold_number}_f1_score\", f1)\n",
    "\n",
    "        break\n",
    "\n",
    "    # Log the best model to MLflow\n",
    "    if best_model is not None:\n",
    "        # Infer model signature\n",
    "        X_train_converted = X_train.copy()\n",
    "        for col in X_train_converted.select_dtypes(include=['category']).columns:\n",
    "            X_train_converted[col] = X_train_converted[col].astype(str)\n",
    "        signature = infer_signature(X_train_converted, best_model.predict(X_train_converted))\n",
    "\n",
    "        # Log the best model to MLflow with the model signature\n",
    "        mlflow.catboost.log_model(best_model, mlflow_model_path, signature=signature)\n",
    "\n",
    "\n",
    "    \n",
    "    # Log plots as artefacts\n",
    "    mlflow.log_artifacts(plots_artefact_path)\n",
    "\n",
    "    # Print the run_id\n",
    "    print(f\"MLflow Run ID: {run.info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hellobetter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
