{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGS\n",
    "dataset_path = 'data\\case_study_example_data.csv'\n",
    "processed_dataset_path = 'data\\processed_dataset.parquet'\n",
    "store_model_path = 'model/best_model.cbm'\n",
    "\n",
    "categorical_columns = ['course', 'gender', 'pre_existing_medical_condition']\n",
    "select_training_columns = ['combined_to_assessment_age', 'course', 'gender', 'combined_age_medical_condition', 'mass_score', 'unsuccessful_outcome']\n",
    "\n",
    "composite_score_ratio_dict = {\n",
    "    'sleep': {\n",
    "        'diary_sleep_avg':0.5,\n",
    "        'diary_stress_avg':0.2 ,\n",
    "        'diary_mood_avg':0.2 ,\n",
    "        'alcohol_scale':0.1 ,\n",
    "    },\n",
    "    'stress': {\n",
    "        'diary_sleep_avg':0.2,\n",
    "        'diary_stress_avg':0.5 ,\n",
    "        'diary_mood_avg':0.2 ,\n",
    "        'alcohol_scale':0.1 ,\n",
    "    },\n",
    "    'depression': {\n",
    "        'diary_sleep_avg':0.2,\n",
    "        'diary_stress_avg':0.2 ,\n",
    "        'diary_mood_avg':0.5 ,\n",
    "        'alcohol_scale':0.1 ,\n",
    "    },\n",
    "    'burnout': {\n",
    "        'diary_sleep_avg':0.2,\n",
    "        'diary_stress_avg':0.5 ,\n",
    "        'diary_mood_avg':0.2 ,\n",
    "        'alcohol_scale':0.1 ,\n",
    "    },\n",
    "    'chronic_pain': {\n",
    "        'diary_sleep_avg':0.3,\n",
    "        'diary_stress_avg':0.3,\n",
    "        'diary_mood_avg':0.3,\n",
    "        'alcohol_scale':0.1,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# MLflow configuration variables\n",
    "use_mlflow = False\n",
    "mlflow_tracking_uri = 'http://localhost:5000'\n",
    "mlflow_experiment_name = 'HelloBetter-Treatment_Outcome_preds'\n",
    "mlflow_register_model_name = 'HelloBetter-Teatment_outcome_predictor'\n",
    "mlflow_model_path = 'model'\n",
    "plots_artefact_path = 'plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, select_cols=select_training_columns):\n",
    "    \"\"\"\n",
    "    Preprocess the health behavior dataset.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): The health behavior DataFrame to preprocess.\n",
    "    select_cols (List): List of columns to be extracted for output dataframe\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The preprocessed dataset.\n",
    "    \"\"\"\n",
    "    # Fill missing data in the dataset\n",
    "    df, _ = knn_impute_missing_data(df)\n",
    "    df, _ = round_columns_to_allowed_values(df, columns_to_round=['alcohol_scale', 'diary_mood_avg', 'diary_sleep_avg', 'diary_stress_avg'])\n",
    "\n",
    "    # Features engineering\n",
    "    df['mass_score'] = df.apply(lambda r: create_mass_score(r), axis=1)\n",
    "    df['combined_age_medical_condition'] = (df['age'] * \n",
    "                                            (1 + 0.5 * df['pre_existing_medical_condition'].apply(lambda v: 1 if v == 'yes' else 0)))\n",
    "    df['combined_to_assessment_age'] = (df['to_assessment'] * (1 - 0.01 * df['age']))\n",
    "\n",
    "    # Transform columns\n",
    "    df['mass_score'] = np.log(df['mass_score'] + 1)\n",
    "    df['combined_age_medical_condition'] = np.log(df['combined_age_medical_condition'] + 1)\n",
    "    df['combined_to_assessment_age'] = np.log(df['combined_to_assessment_age'] + 1)\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute_missing_data(df, categorical_cols=categorical_columns):\n",
    "    \"\"\"\n",
    "    Perform KNN imputation on a DataFrame with categorical features.\n",
    "\n",
    "    This function takes a DataFrame and a list of column names that are categorical.\n",
    "    It encodes the categorical columns using an OrdinalEncoder, then applies KNN imputation.\n",
    "    After imputation, it decodes the categorical features back to their original values.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame with missing values.\n",
    "    - categorical_columns (list of str): The names of the categorical columns in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with imputed values.\n",
    "    - pd.Series: A Series with the count of remaining missing values per column after imputation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate the numerical columns\n",
    "    numerical_columns = df.columns.difference(categorical_columns)\n",
    "\n",
    "    # Initialize the OrdinalEncoder\n",
    "    encoder = OrdinalEncoder()\n",
    "    # Fit and transform the data for categorical columns\n",
    "    data_encoded = df.copy()\n",
    "    data_encoded[categorical_columns] = encoder.fit_transform(df[categorical_columns].astype(str))\n",
    "\n",
    "    # Initialize the KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    # Perform imputation\n",
    "    data_imputed = imputer.fit_transform(data_encoded)\n",
    "\n",
    "    # Convert the imputed data back to a DataFrame and apply inverse transformation for categorical columns\n",
    "    data_imputed = pd.DataFrame(data_imputed, columns=data_encoded.columns)\n",
    "    data_imputed[categorical_columns] = encoder.inverse_transform(data_imputed[categorical_columns])\n",
    "\n",
    "    # Check if there are any missing values left\n",
    "    missing_values_after_imputation = data_imputed.isnull().sum()\n",
    "\n",
    "    return data_imputed, missing_values_after_imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_columns_to_allowed_values(df, columns_to_round, allowed_values= [0, 1, 2, 3, 4, 5]):\n",
    "    \"\"\"\n",
    "    Rounds the values in the specified columns of a DataFrame to the nearest allowed values.\n",
    "\n",
    "    This function applies custom rounding logic to a DataFrame by rounding each value in the \n",
    "    specified columns to the nearest value from a list of allowed values.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing the columns to round.\n",
    "    - columns_to_round (list of str): The names of the columns in the DataFrame to apply rounding to.\n",
    "    - allowed_values (list of numeric): The allowed values that the DataFrame values can be rounded to.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with rounded values.\n",
    "    - dict: A dictionary with column names as keys and arrays of unique values in those columns after rounding.\n",
    "    \"\"\"\n",
    "\n",
    "    def round_to_nearest_allowed_value(x, allowed_values):\n",
    "        return min(allowed_values, key=lambda allowed_value: abs(allowed_value - x))\n",
    "\n",
    "    # Applying the custom rounding to the specified numerical columns\n",
    "    for column in columns_to_round:\n",
    "        df[column] = df[column].apply(round_to_nearest_allowed_value, args=(allowed_values,))\n",
    "\n",
    "    # Check the unique values after rounding to ensure they are within the specified range\n",
    "    unique_values_after_rounding = {column: df[column].unique() for column in columns_to_round}\n",
    "\n",
    "    return df, unique_values_after_rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mass_score(row, ratio_dict=composite_score_ratio_dict):\n",
    "  \"\"\"\n",
    "  Calculate a composite score based on various health metrics and their respective weights.\n",
    "\n",
    "  This function computes a weighted score by multiplying individual health metric values by their\n",
    "  corresponding weights defined in the `ratio_dict`. The health metrics include average sleep, stress, \n",
    "  mood levels, and an alcohol scale. The weights and the metrics are course-specific.\n",
    "\n",
    "  Parameters:\n",
    "  - row (pd.Series): A pandas Series object representing a single row of a DataFrame, \n",
    "                      which should contain the health metrics (diary_sleep_avg, diary_stress_avg,\n",
    "                      diary_mood_avg, alcohol_scale) and a 'course' identifier.\n",
    "  - ratio_dict (dict, optional): A dictionary where each key is a course identifier and \n",
    "                                  the value is another dictionary mapping health metric names to their \n",
    "                                  respective weights. Defaults to `composite_score_ratio_dict` if not provided.\n",
    "\n",
    "  Returns:\n",
    "  float: The calculated composite score for the given row.\n",
    "  \"\"\"\n",
    "  \n",
    "  return (row['diary_sleep_avg'] * ratio_dict[row['course']]['diary_sleep_avg']\n",
    "          + row['diary_stress_avg'] * ratio_dict[row['course']]['diary_stress_avg']\n",
    "          + row['diary_mood_avg'] * ratio_dict[row['course']]['diary_mood_avg']\n",
    "          + row['alcohol_scale'] * ratio_dict[row['course']]['alcohol_scale']\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, y_pred_proba, folder_path=plots_artefact_path, file_name='roc_curve.png'):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(y_test, y_pred_proba, folder_path=plots_artefact_path, file_name='precision_recall_curve.png'):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(recall, precision, color='darkorange', lw=2, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(os.path.join(folder_path, file_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred, folder_path=plots_artefact_path, file_name='confusion_matrix.png'):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(os.path.join(folder_path, file_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(best_model, X_train, folder_path=plots_artefact_path, file_name='feature_importance.png'):\n",
    "    feature_importances = best_model.get_feature_importance()\n",
    "    sorted_indices = feature_importances.argsort()[::-1]\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    plt.title(\"Feature Importances\")\n",
    "    sns.barplot(y=X_train.columns[sorted_indices], x=feature_importances[sorted_indices])\n",
    "    plt.savefig(os.path.join(folder_path, file_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(best_model, folder_path=plots_artefact_path, file_name='learning_curve.png'):\n",
    "    results = best_model.get_evals_result()\n",
    "    epochs = len(results['validation']['AUC'])\n",
    "    x_axis = range(0, epochs)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(x_axis, results['validation']['AUC'], label='Test')\n",
    "    plt.title('CatBoost Learning Curve')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(os.path.join(folder_path, file_name))\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
