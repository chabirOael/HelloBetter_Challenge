{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run ./config.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, select_cols=select_training_columns):\n",
    "    \"\"\"\n",
    "    Preprocess the health behavior dataset.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): The health behavior DataFrame to preprocess.\n",
    "    select_cols (List): List of columns to be extracted for output dataframe\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The preprocessed dataset.\n",
    "    \"\"\"\n",
    "    # Fill missing data in the dataset\n",
    "    df, _ = knn_impute_missing_data(df)\n",
    "    df, _ = round_columns_to_allowed_values(df, columns_to_round=['alcohol_scale', 'diary_mood_avg', 'diary_sleep_avg', 'diary_stress_avg'])\n",
    "\n",
    "    # Features engineering\n",
    "    df['mass_score'] = df.apply(lambda r: create_mass_score(r), axis=1)\n",
    "    df['combined_age_medical_condition'] = (df['age'] * \n",
    "                                            (1 + 0.5 * df['pre_existing_medical_condition'].apply(lambda v: 1 if v == 'yes' else 0)))\n",
    "    df['combined_to_assessment_age'] = (df['to_assessment'] * (1 - 0.01 * df['age']))\n",
    "\n",
    "    # Transform columns\n",
    "    df['mass_score'] = np.log(df['mass_score'] + 1)\n",
    "    df['combined_age_medical_condition'] = np.log(df['combined_age_medical_condition'] + 1)\n",
    "    df['combined_to_assessment_age'] = np.log(df['combined_to_assessment_age'] + 1)\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute_missing_data(df, categorical_cols=categorical_columns):\n",
    "    \"\"\"\n",
    "    Perform KNN imputation on a DataFrame with categorical features.\n",
    "\n",
    "    This function takes a DataFrame and a list of column names that are categorical.\n",
    "    It encodes the categorical columns using an OrdinalEncoder, then applies KNN imputation.\n",
    "    After imputation, it decodes the categorical features back to their original values.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame with missing values.\n",
    "    - categorical_columns (list of str): The names of the categorical columns in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with imputed values.\n",
    "    - pd.Series: A Series with the count of remaining missing values per column after imputation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate the numerical columns\n",
    "    numerical_columns = df.columns.difference(categorical_columns)\n",
    "\n",
    "    # Initialize the OrdinalEncoder\n",
    "    encoder = OrdinalEncoder()\n",
    "    # Fit and transform the data for categorical columns\n",
    "    data_encoded = df.copy()\n",
    "    data_encoded[categorical_columns] = encoder.fit_transform(df[categorical_columns].astype(str))\n",
    "\n",
    "    # Initialize the KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    # Perform imputation\n",
    "    data_imputed = imputer.fit_transform(data_encoded)\n",
    "\n",
    "    # Convert the imputed data back to a DataFrame and apply inverse transformation for categorical columns\n",
    "    data_imputed = pd.DataFrame(data_imputed, columns=data_encoded.columns)\n",
    "    data_imputed[categorical_columns] = encoder.inverse_transform(data_imputed[categorical_columns])\n",
    "\n",
    "    # Check if there are any missing values left\n",
    "    missing_values_after_imputation = data_imputed.isnull().sum()\n",
    "\n",
    "    return data_imputed, missing_values_after_imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_columns_to_allowed_values(df, columns_to_round, allowed_values= [0, 1, 2, 3, 4, 5]):\n",
    "    \"\"\"\n",
    "    Rounds the values in the specified columns of a DataFrame to the nearest allowed values.\n",
    "\n",
    "    This function applies custom rounding logic to a DataFrame by rounding each value in the \n",
    "    specified columns to the nearest value from a list of allowed values.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing the columns to round.\n",
    "    - columns_to_round (list of str): The names of the columns in the DataFrame to apply rounding to.\n",
    "    - allowed_values (list of numeric): The allowed values that the DataFrame values can be rounded to.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with rounded values.\n",
    "    - dict: A dictionary with column names as keys and arrays of unique values in those columns after rounding.\n",
    "    \"\"\"\n",
    "\n",
    "    def round_to_nearest_allowed_value(x, allowed_values):\n",
    "        return min(allowed_values, key=lambda allowed_value: abs(allowed_value - x))\n",
    "\n",
    "    # Applying the custom rounding to the specified numerical columns\n",
    "    for column in columns_to_round:\n",
    "        df[column] = df[column].apply(round_to_nearest_allowed_value, args=(allowed_values,))\n",
    "\n",
    "    # Check the unique values after rounding to ensure they are within the specified range\n",
    "    unique_values_after_rounding = {column: df[column].unique() for column in columns_to_round}\n",
    "\n",
    "    return df, unique_values_after_rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mass_score(row, ratio_dict=composite_score_ratio_dict):\n",
    "  \"\"\"\n",
    "  Calculate a composite score based on various health metrics and their respective weights.\n",
    "\n",
    "  This function computes a weighted score by multiplying individual health metric values by their\n",
    "  corresponding weights defined in the `ratio_dict`. The health metrics include average sleep, stress, \n",
    "  mood levels, and an alcohol scale. The weights and the metrics are course-specific.\n",
    "\n",
    "  Parameters:\n",
    "  - row (pd.Series): A pandas Series object representing a single row of a DataFrame, \n",
    "                      which should contain the health metrics (diary_sleep_avg, diary_stress_avg,\n",
    "                      diary_mood_avg, alcohol_scale) and a 'course' identifier.\n",
    "  - ratio_dict (dict, optional): A dictionary where each key is a course identifier and \n",
    "                                  the value is another dictionary mapping health metric names to their \n",
    "                                  respective weights. Defaults to `composite_score_ratio_dict` if not provided.\n",
    "\n",
    "  Returns:\n",
    "  float: The calculated composite score for the given row.\n",
    "  \"\"\"\n",
    "  \n",
    "  return (row['diary_sleep_avg'] * ratio_dict[row['course']]['diary_sleep_avg']\n",
    "          + row['diary_stress_avg'] * ratio_dict[row['course']]['diary_stress_avg']\n",
    "          + row['diary_mood_avg'] * ratio_dict[row['course']]['diary_mood_avg']\n",
    "          + row['alcohol_scale'] * ratio_dict[row['course']]['alcohol_scale']\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, y_pred_proba, folder_path=mlflow_plots_artefact_path, file_name='roc_curve.png'):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(y_test, y_pred_proba, folder_path=mlflow_plots_artefact_path, file_name='precision_recall_curve.png'):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(recall, precision, color='darkorange', lw=2, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(os.path.join(folder_path, file_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred, folder_path=mlflow_plots_artefact_path, file_name='confusion_matrix.png'):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(os.path.join(folder_path, file_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(best_model, X_train, folder_path=mlflow_plots_artefact_path, file_name='feature_importance.png'):\n",
    "    feature_importances = best_model.get_feature_importance()\n",
    "    sorted_indices = feature_importances.argsort()[::-1]\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    plt.title(\"Feature Importances\")\n",
    "    sns.barplot(y=X_train.columns[sorted_indices], x=feature_importances[sorted_indices])\n",
    "    plt.savefig(os.path.join(folder_path, file_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(best_model, folder_path=mlflow_plots_artefact_path, file_name='learning_curve.png'):\n",
    "    results = best_model.get_evals_result()\n",
    "    epochs = len(results['validation']['AUC'])\n",
    "    x_axis = range(0, epochs)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(x_axis, results['validation']['AUC'], label='Test')\n",
    "    plt.title('CatBoost Learning Curve')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig(os.path.join(folder_path, file_name))\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hellobetter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
